name: PR spam moderation (AI)
on:
  pull_request_target:
    types: [opened, edited, synchronize, reopened]

permissions:
  contents: read
  issues: write
  pull-requests: write
  models: read

jobs:
  moderate-pr:
    runs-on: ubuntu-latest
    env:
      # flip to 'true' only while testing on your own PRs
      ALLOW_CLOSE_TRUSTED: 'true'

    steps:
      - name: Prepare PR context
        id: prep
        uses: actions/github-script@v7
        with:
          script: |
            // ... (unchanged) ...

      - name: Add trigger label
        uses: actions/github-script@v7
        with:
          script: |
            const {owner, repo} = context.repo;
            await github.rest.issues.addLabels({
              owner, repo,
              issue_number: context.payload.pull_request.number,
              labels: ['pr-spam']
            }).catch(()=>{});

      - name: Checkout repo (for prompts)
        uses: actions/checkout@v4
        with:
          ref: ${{ github.event.repository.default_branch }}
          fetch-depth: 1

      - name: AI assess PR
        id: ai
        uses: github/ai-assessment-comment-labeler@main
        with:
          token: ${{ github.token }}
          owner: ${{ github.repository_owner }}
          repo_name: ${{ github.event.repository.name }}
          ai_review_label: pr-spam
          issue_number: ${{ github.event.pull_request.number }}
          issue_body: ${{ steps.prep.outputs.text || github.event.pull_request.body || '(empty)' }}
          prompts_directory: .github/prompts
          labels_to_prompts_mapping: pr-spam,pr-spam.prompt.yml
          suppress_comments: true

      - name: Check collaborator trust
        id: trust
        uses: actions/github-script@v7
        with:
          script: |
            const {owner, repo} = context.repo;
            const user = context.payload.pull_request.user.login;
            let trusted = false;
            try {
              const perm = await github.rest.repos.getCollaboratorPermissionLevel({ owner, repo, username: user });
              trusted = ['admin','maintain','write'].includes(perm.data.permission);
            } catch {}
            core.notice(`trusted=${trusted} user=${user}`);
            core.setOutput('trusted', trusted ? 'true' : 'false');

      - name: Close PR if spam
        # Close when AI says yes AND (author is untrusted OR we explicitly allow during testing)
        if: contains(steps.ai.outputs.ai_assessments, 'ai:pr-spam:yes') && (steps.trust.outputs.trusted == 'false' || env.ALLOW_CLOSE_TRUSTED == 'true')
        uses: actions/github-script@v7
        with:
          script: |
            const {owner, repo} = context.repo;
            const pr = context.payload.pull_request;
            const msg = `Thanks for the PR! We don't accept cosmetic README/docs-only tiny diffs or "add my name" changes.\n\n` +
                        `This was auto-triaged as likely spam. If incorrect, a maintainer can reopen.`;
            await github.rest.issues.createComment({ owner, repo, issue_number: pr.number, body: msg });
            await github.rest.pulls.update({ owner, repo, pull_number: pr.number, state: 'closed' });
